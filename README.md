# data-ethics-final-project

## Process

## Setup 

## Usage

### Create the 1k image dataset 

1. **MTurk_dataset.ipynb** : ran this script to create a folder containing the 1k images (1k-MTurk-Images). Also creates a csv that contains the relevant attributes (attractive, race, memorable), the corresponding original filename from the 10K face dataset, and the link to the file on the AWS bucket. 

2. **MTurk_experiment.html** : created an experiment on CloudResearch using this HTML file and the 1k-images.csv. 

### Clean the 1K CloudResearch Survey 
Directory: 1k_CloudResearch_study

1. Downloaded the results of the CloudResearch survey into this directory and renamed the CSVs using the convention 1k_dataset_<number>.csv. 
2. **1k_CLoudResearch_study/1k_image_data_processing.ipynb**: Ran this notebook to clean and process the CloudResearch data. This notebook also creates a second survey CSV (excluding the images from the first CSV) since we were not able to collect all of the data with one survey. exclude_participants.txt was generated by the notebook and used to ensure that participants who already took the survey could not take it again. This txt file was uploaded along with 1k_dataset_2.csv to a new CloudResearch study. These datasets were merged in the notebook. This notebook outputs a cleaned CloudResearch dataset to 1k_CLoudResearch_study/1k_dataset_output.csv. for use in DALL-E prompting. 

### Generate and Transform Reconstructed DALL-E Face Images
Directories: Project root, DALLE_images, TRANSFORMED_DALLE_images

1. **image_dataset_transformer.ipynb**: ran this notebook to generate and transform the DALLE images based on the facial descriptions of each row in 1k_CLoudResearch_study/1k_dataset_output.csv. Some descriptions threw Content Policy Violation errors due to the facial descriptions in the prompt, so images could not be generated for these rows. DALL-E images are saved as jpgs and written to the folder DALLE_images. After DALLE photos are generated, they are transformed to fit the dimensions and style of the original image. The DALLE images are cropped to the same dimensions as their corresponding original image, and a rudimentary version of the white oval (that covers the background of the original image) is applied to the DALL-E image to ensure similarity / accuracy is not confounded by white space. The transformed DALLE images are saved to the directory TRANSFORMED_DALLE_images

### Implement CNN and quantify the similarity between AI generated image and original image 
Directory: 1k-MTurk-Images-Experiment, TRANSFORMED_DALLE_images, image_feature_df

1. **data_ethics_project_cnn_post_model_analysis.ipynb**: Ran this notebook to implement the CLIP CNN as well as determine the cosine similarity for each original image and AI-generated image. To run the CNN, we first used the dataframes containing the filenames for each real and AI-generated image and then retrieved the corresponding image from the 1k-MTurk-Images-Experiment and TRANSFORMED_DALLE_images directories. After preprocessing and encoding the PIL image, we stored the encoded image features into rows. This process yielded two separate output dataframes of features (one for the real image feature and one for the AI-generated image features), which we then saved as CSVs into the directory image_feature_df. With the image feature dataframes, we calculated the cosine similarity between the real image and AI-generated image by applying the cosine similarity function for each element in the dataframes. This resulted in a list of similarity scores, where each score corresponded to a real image-AI Image pair.

### Determining Statistical Significance:
Directory: 

1. **data_ethics_project_cnn_post_model_analysis.ipynb**: Ran this Colab notebook to generate histograms of the distribution of similarity scores across different memorability and race groups. Furthermore, this notebook also generated a nested list, where each list item contained the similarity scores for each memorability-race group pairing. The memorability scores were constricted to 2.0, 3.0, and 4.0, as similarity scores of 1.0 and 5.0 had non-normal distributions. From there, we preprocessed the nested list for ANOVA testing by creating a dataframe and then melting it to just include a column for treatment and similarity score. Finally, we copied the dataframe into a textile, which was exported to R for statistical analysis.

2. **data_ethics_final_results.Rmd**: Ran this notebook to perform a one-way ANOVA test on the different memorability-race groups. After reading in the text, we performed the Box Cox method and determined that the groups violated the constant variance assumption. To account for unequal variance, we transformed the Similarity Score variable in our analysis. We then fitted the transformed data into a linear model and then generated the ANOVA table. Furthermore, to identify specific differences in means across pairs of groups, we also performed a pairwise comparison at the 5% significance level. 


