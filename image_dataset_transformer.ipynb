{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#from openai import OpenAI\n",
    "from collections.abc import MutableMapping\n",
    "import json\n",
    "#!pip install openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import openai\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "#!pip install opencv-python\n",
    "from PIL import Image\n",
    "import collections\n",
    "import math\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing if image opens properly... \n",
    "# Imports PIL module  \n",
    "from PIL import Image \n",
    "  \n",
    "# open method used to open different extension image file \n",
    "im = Image.open(data[\"filepath_og_img\"][1])  \n",
    "  \n",
    "# This method will show image in any image viewer  \n",
    "im.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the CloudResearch Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading response data\n",
    "output_file_path = \"1k_CloudResearch_study/1k_dataset_output.csv\"\n",
    "data = pd.read_csv(output_file_path)\n",
    "\n",
    "#Filling additional info description box with string\n",
    "data.fillna(\"No description provided\", inplace = True)\n",
    "\n",
    "# create the relative file_path of the image to access w/ DALLE\n",
    "data[\"Filepath_og_img\"] = data[\"Filename_og_img\"].apply(lambda file: \"1k-MTurk-Images/\" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.iloc[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_description</th>\n",
       "      <th>jaw_description</th>\n",
       "      <th>eyes_description</th>\n",
       "      <th>hair_description</th>\n",
       "      <th>nose_description</th>\n",
       "      <th>race_description</th>\n",
       "      <th>beard_description</th>\n",
       "      <th>gender_description</th>\n",
       "      <th>eyebrows_description</th>\n",
       "      <th>expression_description</th>\n",
       "      <th>...</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Occupation Field</th>\n",
       "      <th>Relationship/Marital Status</th>\n",
       "      <th>Political Party</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Country Of Residence</th>\n",
       "      <th>Household Income</th>\n",
       "      <th>Race</th>\n",
       "      <th>Employment Status</th>\n",
       "      <th>Filepath_og_img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mid 30s</td>\n",
       "      <td>pointed, soft</td>\n",
       "      <td>small, brown, friendly</td>\n",
       "      <td>short, brown, straight</td>\n",
       "      <td>wide, small nostrils</td>\n",
       "      <td>white</td>\n",
       "      <td>brown, scruffy, mustash</td>\n",
       "      <td>male</td>\n",
       "      <td>brown, whispy</td>\n",
       "      <td>smiling</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>Education &amp; Training</td>\n",
       "      <td>Married</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Woman</td>\n",
       "      <td>United States</td>\n",
       "      <td>$100,000-$124,999</td>\n",
       "      <td>White</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>1k-MTurk-Images/Google_1_Louis Sung_1_oval.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90's</td>\n",
       "      <td>a round jaw</td>\n",
       "      <td>light blue eyes</td>\n",
       "      <td>short cropped hair</td>\n",
       "      <td>wide nose</td>\n",
       "      <td>black</td>\n",
       "      <td>no beard</td>\n",
       "      <td>female</td>\n",
       "      <td>thinning light brows</td>\n",
       "      <td>smiling</td>\n",
       "      <td>...</td>\n",
       "      <td>Female</td>\n",
       "      <td>Retail</td>\n",
       "      <td>In a relationship</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>Woman</td>\n",
       "      <td>United States</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>White</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>1k-MTurk-Images/Google_1_Lorraine Byrd_9_oval.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  age_description jaw_description        eyes_description  \\\n",
       "1         mid 30s   pointed, soft  small, brown, friendly   \n",
       "2            90's     a round jaw         light blue eyes   \n",
       "\n",
       "         hair_description      nose_description race_description  \\\n",
       "1  short, brown, straight  wide, small nostrils            white   \n",
       "2      short cropped hair             wide nose            black   \n",
       "\n",
       "         beard_description gender_description  eyebrows_description  \\\n",
       "1  brown, scruffy, mustash               male         brown, whispy   \n",
       "2                 no beard             female  thinning light brows   \n",
       "\n",
       "  expression_description  ...     Sex      Occupation Field  \\\n",
       "1                smiling  ...  Female  Education & Training   \n",
       "2                smiling  ...  Female                Retail   \n",
       "\n",
       "   Relationship/Marital Status    Political Party Gender Country Of Residence  \\\n",
       "1                      Married        Independent  Woman        United States   \n",
       "2            In a relationship  Prefer not to say  Woman        United States   \n",
       "\n",
       "    Household Income   Race Employment Status  \\\n",
       "1  $100,000-$124,999  White         Full-time   \n",
       "2  Prefer not to say  White         Full-time   \n",
       "\n",
       "                                     Filepath_og_img  \n",
       "1     1k-MTurk-Images/Google_1_Louis Sung_1_oval.jpg  \n",
       "2  1k-MTurk-Images/Google_1_Lorraine Byrd_9_oval.jpg  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating DALLE Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new folder for the target directory that contains the DALLE images if it does not exist\n",
    "target_folder = \"DALLE_images\" \n",
    "current_directory = os.getcwd()\n",
    "final_directory = os.path.join(current_directory, target_folder)\n",
    "if not os.path.exists(final_directory):\n",
    "   os.makedirs(final_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_description</th>\n",
       "      <th>jaw_description</th>\n",
       "      <th>eyes_description</th>\n",
       "      <th>hair_description</th>\n",
       "      <th>nose_description</th>\n",
       "      <th>race_description</th>\n",
       "      <th>beard_description</th>\n",
       "      <th>gender_description</th>\n",
       "      <th>eyebrows_description</th>\n",
       "      <th>expression_description</th>\n",
       "      <th>additionalInfo_description</th>\n",
       "      <th>Attractive_og_img</th>\n",
       "      <th>Race_og_img</th>\n",
       "      <th>Memorable_og_img</th>\n",
       "      <th>Filename_og_img</th>\n",
       "      <th>AWSFile_og_img</th>\n",
       "      <th>Task Data</th>\n",
       "      <th>Submitted Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40s</td>\n",
       "      <td>Rounded</td>\n",
       "      <td>Hazel</td>\n",
       "      <td>Brown short</td>\n",
       "      <td>Smaller sharp</td>\n",
       "      <td>white</td>\n",
       "      <td>None</td>\n",
       "      <td>female</td>\n",
       "      <td>Brown</td>\n",
       "      <td>smiling</td>\n",
       "      <td>No description provided</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Google_1_Jane Standifer_11_oval.jpg</td>\n",
       "      <td>https://mturk-1k-images.s3.amazonaws.com/Googl...</td>\n",
       "      <td>{\"RowData\":[{\"CellData\":\"4.0\",\"ColumnHeader\":\"...</td>\n",
       "      <td>{\"Data\":{\"taskData\":{\"age\":\"40s\",\"jaw\":\"Rounde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mid 30s</td>\n",
       "      <td>pointed, soft</td>\n",
       "      <td>small, brown, friendly</td>\n",
       "      <td>short, brown, straight</td>\n",
       "      <td>wide, small nostrils</td>\n",
       "      <td>white</td>\n",
       "      <td>brown, scruffy, mustash</td>\n",
       "      <td>male</td>\n",
       "      <td>brown, whispy</td>\n",
       "      <td>smiling</td>\n",
       "      <td>not weraling anything else, flat ears</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Google_1_Louis Sung_1_oval.jpg</td>\n",
       "      <td>https://mturk-1k-images.s3.amazonaws.com/Googl...</td>\n",
       "      <td>{\"RowData\":[{\"CellData\":\"4.0\",\"ColumnHeader\":\"...</td>\n",
       "      <td>{\"Data\":{\"taskData\":{\"age\":\"mid 30s\",\"jaw\":\"po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90's</td>\n",
       "      <td>a round jaw</td>\n",
       "      <td>light blue eyes</td>\n",
       "      <td>short cropped hair</td>\n",
       "      <td>wide nose</td>\n",
       "      <td>black</td>\n",
       "      <td>no beard</td>\n",
       "      <td>female</td>\n",
       "      <td>thinning light brows</td>\n",
       "      <td>smiling</td>\n",
       "      <td>wearing earrings and smiling</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Google_1_Lorraine Byrd_9_oval.jpg</td>\n",
       "      <td>https://mturk-1k-images.s3.amazonaws.com/Googl...</td>\n",
       "      <td>{\"RowData\":[{\"CellData\":\"3.0\",\"ColumnHeader\":\"...</td>\n",
       "      <td>{\"Data\":{\"taskData\":{\"age\":\"90\\u0027s\",\"jaw\":\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>Roundish</td>\n",
       "      <td>Hazel</td>\n",
       "      <td>Gray</td>\n",
       "      <td>Average</td>\n",
       "      <td>white</td>\n",
       "      <td>Slight gray</td>\n",
       "      <td>male</td>\n",
       "      <td>Gray</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Seemed to be wea</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Adam_Koester_6_oval.jpg</td>\n",
       "      <td>https://mturk-1k-images.s3.amazonaws.com/Adam_...</td>\n",
       "      <td>{\"RowData\":[{\"CellData\":\"3.0\",\"ColumnHeader\":\"...</td>\n",
       "      <td>{\"Data\":{\"taskData\":{\"age\":\"42\",\"jaw\":\"Roundis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>Wide</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Narrow</td>\n",
       "      <td>white</td>\n",
       "      <td>Shaved</td>\n",
       "      <td>male</td>\n",
       "      <td>Narrow</td>\n",
       "      <td>smiling</td>\n",
       "      <td>No description provided</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Google_1_Joe Amaral_3_oval.jpg</td>\n",
       "      <td>https://mturk-1k-images.s3.amazonaws.com/Googl...</td>\n",
       "      <td>{\"RowData\":[{\"CellData\":\"3.0\",\"ColumnHeader\":\"...</td>\n",
       "      <td>{\"Data\":{\"taskData\":{\"age\":\"37\",\"jaw\":\"Wide\",\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age_description jaw_description        eyes_description  \\\n",
       "0             40s         Rounded                   Hazel   \n",
       "1         mid 30s   pointed, soft  small, brown, friendly   \n",
       "2            90's     a round jaw         light blue eyes   \n",
       "3              42        Roundish                   Hazel   \n",
       "4              37            Wide                   Brown   \n",
       "\n",
       "         hair_description      nose_description race_description  \\\n",
       "0             Brown short         Smaller sharp            white   \n",
       "1  short, brown, straight  wide, small nostrils            white   \n",
       "2      short cropped hair             wide nose            black   \n",
       "3                    Gray               Average            white   \n",
       "4                   Brown                Narrow            white   \n",
       "\n",
       "         beard_description gender_description  eyebrows_description  \\\n",
       "0                     None             female                 Brown   \n",
       "1  brown, scruffy, mustash               male         brown, whispy   \n",
       "2                 no beard             female  thinning light brows   \n",
       "3              Slight gray               male                  Gray   \n",
       "4                   Shaved               male                Narrow   \n",
       "\n",
       "  expression_description             additionalInfo_description  \\\n",
       "0                smiling                No description provided   \n",
       "1                smiling  not weraling anything else, flat ears   \n",
       "2                smiling           wearing earrings and smiling   \n",
       "3                neutral                       Seemed to be wea   \n",
       "4                smiling                No description provided   \n",
       "\n",
       "   Attractive_og_img  Race_og_img  Memorable_og_img  \\\n",
       "0                4.0          1.0               4.0   \n",
       "1                4.0          1.0               5.0   \n",
       "2                3.0          2.0               4.0   \n",
       "3                3.0          1.0               3.0   \n",
       "4                3.0          5.0               3.0   \n",
       "\n",
       "                       Filename_og_img  \\\n",
       "0  Google_1_Jane Standifer_11_oval.jpg   \n",
       "1       Google_1_Louis Sung_1_oval.jpg   \n",
       "2    Google_1_Lorraine Byrd_9_oval.jpg   \n",
       "3              Adam_Koester_6_oval.jpg   \n",
       "4       Google_1_Joe Amaral_3_oval.jpg   \n",
       "\n",
       "                                      AWSFile_og_img  \\\n",
       "0  https://mturk-1k-images.s3.amazonaws.com/Googl...   \n",
       "1  https://mturk-1k-images.s3.amazonaws.com/Googl...   \n",
       "2  https://mturk-1k-images.s3.amazonaws.com/Googl...   \n",
       "3  https://mturk-1k-images.s3.amazonaws.com/Adam_...   \n",
       "4  https://mturk-1k-images.s3.amazonaws.com/Googl...   \n",
       "\n",
       "                                           Task Data  \\\n",
       "0  {\"RowData\":[{\"CellData\":\"4.0\",\"ColumnHeader\":\"...   \n",
       "1  {\"RowData\":[{\"CellData\":\"4.0\",\"ColumnHeader\":\"...   \n",
       "2  {\"RowData\":[{\"CellData\":\"3.0\",\"ColumnHeader\":\"...   \n",
       "3  {\"RowData\":[{\"CellData\":\"3.0\",\"ColumnHeader\":\"...   \n",
       "4  {\"RowData\":[{\"CellData\":\"3.0\",\"ColumnHeader\":\"...   \n",
       "\n",
       "                                      Submitted Data  \n",
       "0  {\"Data\":{\"taskData\":{\"age\":\"40s\",\"jaw\":\"Rounde...  \n",
       "1  {\"Data\":{\"taskData\":{\"age\":\"mid 30s\",\"jaw\":\"po...  \n",
       "2  {\"Data\":{\"taskData\":{\"age\":\"90\\u0027s\",\"jaw\":\"...  \n",
       "3  {\"Data\":{\"taskData\":{\"age\":\"42\",\"jaw\":\"Roundis...  \n",
       "4  {\"Data\":{\"taskData\":{\"age\":\"37\",\"jaw\":\"Wide\",\"...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google_1_Jane Standifer_11_oval_DALLE.jpg'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = test_data.iloc[0]\n",
    "testing_name = testing[\"Filename_og_img\"]\n",
    "testing_name.split(\".jpg\")[0] + \"_DALLE.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def convert_to_jpg(url, output_path):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            image.save(output_path, 'JPEG')\n",
    "            print(f\"Image saved as {output_path}\")\n",
    "            return output_path\n",
    "        else:\n",
    "            print(\"Failed to download image from URL.\")\n",
    "    except Exception as e:\n",
    "        print(f\"A error occurred: {e}\")\n",
    "        return \"error\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new folder for the target directory that contains the images\n",
    "target_folder = \"DALLE_images\"\n",
    "current_directory = os.getcwd()\n",
    "final_directory = os.path.join(current_directory, target_folder)\n",
    "if not os.path.exists(final_directory):\n",
    "   os.makedirs(final_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DALLE_images/1k_survey_2.csv_DALLE.jpg'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"1k_CloudResearch_study/1k_survey_2.csv\"\n",
    "file_name = path.split(\"/\")[1]\n",
    "new_file_name = file_name.split(\".jpg\")[0] + \"_DALLE.jpg\"\n",
    "output_path = \"DALLE_images/\" + new_file_name\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_description                                                               42\n",
       "jaw_description                                                         Roundish\n",
       "eyes_description                                                           Hazel\n",
       "hair_description                                                            Gray\n",
       "nose_description                                                         Average\n",
       "race_description                                                           white\n",
       "beard_description                                                    Slight gray\n",
       "gender_description                                                          male\n",
       "eyebrows_description                                                        Gray\n",
       "expression_description                                                   neutral\n",
       "additionalInfo_description                                      Seemed to be wea\n",
       "Attractive_og_img                                                            3.0\n",
       "Race_og_img                                                                  1.0\n",
       "Memorable_og_img                                                             3.0\n",
       "Filename_og_img                                          Adam_Koester_6_oval.jpg\n",
       "AWSFile_og_img                 https://mturk-1k-images.s3.amazonaws.com/Adam_...\n",
       "ParticipantId                                   66069B9E28EE4DA69951BD77656028ED\n",
       "Task Data                      {\"RowData\":[{\"CellData\":\"3.0\",\"ColumnHeader\":\"...\n",
       "Submitted Data                 {\"Data\":{\"taskData\":{\"age\":\"42\",\"jaw\":\"Roundis...\n",
       "Age                                                                           36\n",
       "Education                      High school graduate - high school diploma or ...\n",
       "Sex                                                                         Male\n",
       "Occupation Field                                                           Other\n",
       "Relationship/Marital Status                                               Single\n",
       "Political Party                                                         Democrat\n",
       "Gender                                                                       Man\n",
       "Country Of Residence                                               United States\n",
       "Household Income                                                 $20,000-$29,999\n",
       "Race                                                   Black or African American\n",
       "Employment Status                                                        Student\n",
       "Filepath_og_img                          1k-MTurk-Images/Adam_Koester_6_oval.jpg\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_DALLE_image(row):\n",
    "    prompt = (\"Photo of a human face by photographer Anna-Lou Leibovitz against a white backdrop, with a camera angle of 80mm at eye level, while also containing the follwing features: \" \n",
    "              +  row['gender_description'] + \"; Age: \" + row['age_description'] + \"; Race: \" \n",
    "              + row['race_description'] + \"; Hair: \" + row['hair_description'] + \"; Eyebrows: \" \n",
    "              + row['eyebrows_description'] + \"; Eyes: \" + row[\"eyes_description\"] + \"; Nose: \" \n",
    "              + row[\"nose_description\"] + \"; Jaw: \" +  row['jaw_description'] + \"; Expression: \" + row[\"expression_description\"] +\n",
    "    \"; Beard: \" + row['beard_description'] + \"; Additional Info: \" + row['additionalInfo_description'])\n",
    "\n",
    "    OPENAI_API_KEY = \"key\"\n",
    "\n",
    "    client = OpenAI(api_key = OPENAI_API_KEY)\n",
    "\n",
    "    try: \n",
    "        # generate image for each user prompt\n",
    "        response = client.images.generate(\n",
    "            model=\"dall-e-2\",\n",
    "            prompt= prompt,\n",
    "            size=\"256x256\",\n",
    "            quality=\"standard\",\n",
    "            n=1,\n",
    "        )\n",
    "        \n",
    "        url = response.data[0].url\n",
    "    except openai.RateLimitError as error:\n",
    "        # Handle the RateLimitError here\n",
    "        print(\"Rate limit exceeded:\", error)\n",
    "    except: \n",
    "        print(\"a content error occurred\")\n",
    "        return(\"content error\")\n",
    "\n",
    "    # converting DALLE image to jpg and saving to DALLE_images folder \n",
    "    file_name = row[\"Filepath_og_img\"]\n",
    "    file_name = file_name.split(\"/\")[1]\n",
    "    new_file_name = file_name.split(\".jpg\")[0] + \"_DALLE.jpg\"\n",
    "    output_path = \"DALLE_images/\" + new_file_name\n",
    "    DALLE_file_path = convert_to_jpg(url, output_path)\n",
    "\n",
    "    return DALLE_file_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to figure out how to time this so it makes each request properly \n",
    "#data[\"DALLE_image_path\"] = data.apply(lambda row: generate_and_save_DALLE_image(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def create_DALLE_images(df):\n",
    "    \"\"\"\n",
    "    Applies the generate_and_save_DALLE_image fx to stay w/in the openai rate limit \n",
    "    \"\"\"\n",
    "    # Initialize variables for rate limiting\n",
    "    start_time = time.time()\n",
    "    image_count = 0\n",
    "    DALLE_file_paths = []\n",
    "    # Iterate over each row in the dataframe\n",
    "    for index, row in df.iterrows():\n",
    "        DALLE_file_path = generate_and_save_DALLE_image(row)\n",
    "        DALLE_file_paths.append(DALLE_file_path)\n",
    "        # Apply DALL-E function to the current row\n",
    "        # Replace the placeholder function call with your DALL-E function call\n",
    "        # dalle_output = your_dalle_function(row['column_name'])\n",
    "\n",
    "        # Simulate DALL-E function call with a sleep of 1 second\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Update image count and check rate limit\n",
    "        image_count += 1\n",
    "        if image_count >= 5:\n",
    "            # If rate limit exceeded, wait until the next minute\n",
    "            elapsed_time = time.time() - start_time\n",
    "            if elapsed_time < 60:\n",
    "                time.sleep(60 - elapsed_time)\n",
    "            # Reset image count and start time\n",
    "            image_count = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Processed {index + 1} rows\")\n",
    "    \n",
    "    # creating a new column in the df with the corresponding file paths\n",
    "    df[\"DALLE_image_path\"] = DALLE_file_paths\n",
    "    print(\"DALLE image processing completed.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a content error occurred\n",
      "Processed 2 rows\n",
      "Image saved as DALLE_images/Google_1_Lorraine Byrd_9_oval_DALLE.jpg\n",
      "Processed 3 rows\n",
      "DALLE image processing completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wz/7k6v05bx5gvffw4vkwfkmkn40000gn/T/ipykernel_66122/2010554336.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"DALLE_image_path\"] = DALLE_file_paths\n"
     ]
    }
   ],
   "source": [
    "# need to figure out how to time this so it makes each request properly \n",
    "test_data = create_DALLE_images(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardizing DALLE Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### methods to crop images and add oval to match the og image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "def crop_image(og_image_file, DALLE_image_file):\n",
    "    \"\"\"\n",
    "    Crops the DALLE image according to the dimensions of the original image \n",
    "    Args: \n",
    "        og_image: filename of original image\n",
    "        DALLE_image: filename of DALLE image\n",
    "\n",
    "    Returns: \n",
    "        Path of new cropped DALLE image file \n",
    "    \"\"\"\n",
    "\n",
    "    # Open the original image\n",
    "    og_image = Image.open(og_image_file)\n",
    "    width_og, height_og = og_image.size\n",
    "\n",
    "    # Open the DALLE image\n",
    "    DALLE_image = Image.open(DALLE_image_file)\n",
    "    width, height = DALLE_image.size\n",
    "\n",
    "    # Calculate the dimensions for cropping\n",
    "    width_diff = width - width_og\n",
    "    height_diff = height - height_og\n",
    "    width_diff_one_side = width_diff / 2\n",
    "    height_diff_one_side = height_diff / 2\n",
    "\n",
    "    # Ensure the image is larger than the original image\n",
    "    if width_diff < 0 or height_diff < 0:\n",
    "        print(\"Error: Cropped area is larger than the original image.\")\n",
    "        return None\n",
    "\n",
    "    # Calculate the cropping coordinates\n",
    "    left = math.floor(width_diff_one_side)\n",
    "    right = width - math.floor(width_diff_one_side)\n",
    "    top = math.floor(height_diff_one_side)\n",
    "    bottom = height - math.floor(height_diff_one_side)\n",
    "\n",
    "    # Perform the cropping\n",
    "    cropped_img = DALLE_image.crop((left, top, right, bottom))\n",
    "\n",
    "    # Save the cropped image\n",
    "    file_name = DALLE_image_file.split(\"/\")[-1]  \n",
    "    path = file_name.split(\".\")[0]\n",
    "    transformed_image_path = \"TRANSFORMED_DALLE_images/\" + path + \"_TRANSFORMED.jpg\"\n",
    "    cropped_img.save(transformed_image_path)\n",
    "    \n",
    "    return transformed_image_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_pixels(image_file):\n",
    "    # Open the image\n",
    "    im = Image.open(image_file)\n",
    "\n",
    "    # Load pixel data\n",
    "    pix = im.load()\n",
    "\n",
    "    # Get the width and height of the image\n",
    "    width, height = im.size\n",
    "\n",
    "    # Create a 2D array to store pixel values\n",
    "    pixels_2d = [[0 for _ in range(width)] for _ in range(height)]\n",
    "\n",
    "    # Iterate over each pixel and store its RGBA values in the 2D array\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            pixels_2d[y][x] = pix[x, y]\n",
    "\n",
    "    return pixels_2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_from_arr(image_path, pixels_2d):\n",
    "    # Assuming pixels_2d is your 2D array of pixels\n",
    "    # Example pixels_2d = [[(255, 255, 255), (0, 0, 0), ...], [...], ...]\n",
    "\n",
    "    # Assuming width and height are the dimensions of your image\n",
    "    width, height = len(pixels_2d[0]), len(pixels_2d)\n",
    "\n",
    "    # Create a new image\n",
    "    new_im = Image.new(\"RGB\", (width, height))\n",
    "\n",
    "    # Load pixel data\n",
    "    pix = new_im.load()\n",
    "\n",
    "    # Set pixel values\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            pix[x, y] = pixels_2d[y][x]\n",
    "\n",
    "    # Save the image to a file\n",
    "    new_im.save(image_path)\n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_white_oval(og_image_file, AI_image_file):\n",
    "    \"\"\"\n",
    "    Uses breadth-first search to identify the white oval frame in the og image and apply it to the AI generated image\n",
    "    og_image_file, AI_image_file\n",
    "    \"\"\"\n",
    "\n",
    "    # getting the 2d array of pixels from each image\n",
    "    og_image_pixels = get_image_pixels(og_image_file)\n",
    "    AI_image_pixels = get_image_pixels(AI_image_file)\n",
    "\n",
    "    rows, cols = len(og_image_pixels), len(og_image_pixels[0])\n",
    "    rows1, cols1 = len(AI_image_pixels), len(AI_image_pixels[1])\n",
    "    print(rows, cols, rows1, cols1)\n",
    "    \n",
    "    visited = set()\n",
    "\n",
    "    def bfs(r, c):\n",
    "        q = collections.deque()\n",
    "        visited.add((r, c))\n",
    "        q.append((r, c))\n",
    "\n",
    "        while q:\n",
    "            row, col = q.popleft()\n",
    "            directions = [[1, 0], [-1, 0], [0, 1], [0, -1]]\n",
    "\n",
    "            for dr, dc in directions:\n",
    "                r, c = row + dr, col + dc\n",
    "                if (r in range(rows) \n",
    "                    and c in range(cols) \n",
    "                    and og_image_pixels[r][c] == (255, 255, 255)\n",
    "                    and (r, c) not in visited):\n",
    "                    q.append((r, c))\n",
    "                    visited.add((r, c))\n",
    "                    AI_image_pixels[r][c] = (255, 255, 255)\n",
    "\n",
    "    # breadth first search starting from the corners of the image (to capture the oval)\n",
    "    bfs(0, 0)\n",
    "    bfs(rows - 1, 0)\n",
    "    bfs(0, cols - 1)\n",
    "    bfs(rows - 1, cols - 1)\n",
    "    output_image_path = create_image_from_arr(AI_image_file, AI_image_pixels)\n",
    "    return output_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_DALLE_image(og_image_file, DALLE_image_file):\n",
    "    \"\"\"\n",
    "    Standardizes the DALLE image by cropping to fit dimensions of original image and applying the white oval\n",
    "    \"\"\"\n",
    "    cropped_image = crop_image(og_image_file, DALLE_image_file)\n",
    "    transformed_image_path = apply_white_oval(og_image_file, cropped_image)\n",
    "    return transformed_image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implementing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new folder for the target directory that contains the transformed images if it does not exist\n",
    "target_folder = \"TRANSFORMED_DALLE_images\" \n",
    "current_directory = os.getcwd()\n",
    "final_directory = os.path.join(current_directory, target_folder)\n",
    "if not os.path.exists(final_directory):\n",
    "   os.makedirs(final_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 209 256 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wz/7k6v05bx5gvffw4vkwfkmkn40000gn/T/ipykernel_66122/1939585345.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data[\"DALLE_images_transformed\"] = test_data.apply(lambda row: transform_DALLE_image(row[\"Filepath_og_img\"], row[\"DALLE_image_path\"])\n"
     ]
    }
   ],
   "source": [
    "test_data[\"DALLE_images_transformed\"] = test_data.apply(lambda row: transform_DALLE_image(row[\"Filepath_og_img\"], row[\"DALLE_image_path\"]) \n",
    "                                                        if row[\"DALLE_image_path\"] != \"error occurred\" \n",
    "                                                        else row[\"DALLE_image_path\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
